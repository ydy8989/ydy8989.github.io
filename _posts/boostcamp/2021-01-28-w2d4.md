---
layout: post
title: Pandas II & 확률론 맛보기 
subtitle: Pandas의 마지막과 확률론
gh-repo: ydy8989/ydy8989.github.io
gh-badge: [follow]
categories: [BOOSTCAMP]
tags: [boostcamp]
comments: true
---
pandas I 강의에 이어서 pandas 라이브러리의 다음과 같은 기능에 대해 알아봅니다. 또한 딥러닝의 기본 바탕이되는 확률론에 대해 소개합니다. **확률분포, 조건부확률, 기대값**의 개념과 **몬테카를로 샘플링** 방법을 설명합니다. 데이터의 초상화로써 확률분포가 가지는 의미와 이에 따라 분류될 수 있는 이산확률변수, 연속확률변수의 차이점에 대해 설명합니다.

 

확률변수, 조건부확률, 기대값 등은 확률론의 매우 기초적인 내용이며 이를 정확히 이해하셔야 바로 다음 강의에서 배우실 통계학으로 이어질 수 있습니다. 기대값을 계산하는 방법, 특히 확률분포를 모를 때 몬테카를로 방법을 통해 기댓값을 계산하는 방법 등은 머신러닝에서 매우 빈번하게 사용되므로 본 포스팅 이외에도 충분히 공부하는 것을 추천합니다.

> 강의에서 사용 될 예제 코드는 **[여기](https://github.com/BoostcampAITech/lecture-note-python-basics-for-ai/tree/main/codes/pandas/part_2)**에서 확인 가능합니다. 

<br>

# 1. groupby

- 묶음의 기준이 되는 컬럼에 적용받는 컬럼을 어떻게할지

- ```python
  df.groupby('team')['Point'].sum()
  ```

  > ![image-20210128155107847](https://user-images.githubusercontent.com/38639633/106174269-2c5c2a80-61d8-11eb-98d5-1110d4e41d8f.png){: width="45%"}{: .center}![image-20210128155113720](https://user-images.githubusercontent.com/38639633/106176866-2c115e80-61db-11eb-98ff-ad7c5d963a33.png){: width="45%"}{: .center}

- 한 개 이상의 Column을 묶을 수도 있다. 

  ```python
  df.groupby(['Team','Year'])['Point'].sum()
  ```

  > ![image-20210128155450884](https://user-images.githubusercontent.com/38639633/106174324-43028180-61d8-11eb-830a-3b488ecd778c.png)

<br>

## 1.1. Hierarchical index

- Goupby 명령의 결과물도 결국에는 DataFrame이다. 

- 두 개의 column으로 groupby를 할 경우, index가 두 개 생성된다.

  > ![image-20210128155947558](https://user-images.githubusercontent.com/38639633/106174349-48f86280-61d8-11eb-8b75-80465ea0ea56.png)

- **unstack()**

  - Group으로 묶여진 데이터를 matrix 형태로 전환해준다. 

    > ![image-20210128160055110](https://user-images.githubusercontent.com/38639633/106174370-501f7080-61d8-11eb-8dc8-fb42d71718b0.png)

- **swaplevel()**

  - Index level을 변경할 수 있다. 
    - Multi index의 경우 `index1, index2` => `index2, index1` 의 순서로 변경

- **operations**

  - Index level을 기준으로 기본 연산수행이 가능하다. 

    ```python
    h_index.sum(level = 0) # 1번째 인덱스를 기준으로 summation
    h_index.sum(level = 1) # 2번째 인덱스를 기준으로 summation
    ```

<br>

## 1.2. grouped

- Groupby에 의해 Split된 상태를 추출할 수 있다. 

  ```python
  grouped = df.groupby('Team')
  for name, group in grouped:
      print(name)
      print(group)
  ```

  > ![image-20210128185034495](https://user-images.githubusercontent.com/38639633/106174424-5f062300-61d8-11eb-9e77-0595e6581b74.png)

- 특정 key값을 가진 그룹의 정보만 추출 가능하다.

  ```python
  grouped.get_group("Devils")
  ```

  > - `.get_group()`로 해당 group에 대한 정보만 추출한 모습
  >
  > ![image-20210128185056706](https://user-images.githubusercontent.com/38639633/106174443-64636d80-61d8-11eb-9a79-bcbf98cacf7b.png)

- 추출된 group 정보에는 세 가지 유형의 apply가 가능하다.

  > 1. Aggregation : 요약된 통계 정보를 추출해줌
  > 2. Transformation :  해당 정보를 변환해줌
  > 3. Filtration : 특정 정보를 제거하여 보여주는 필터링 기능

<br>



### Aggregation(.agg(연산명))

- ```python
  grouped.agg(max)
  ```

  > ![image-20210128185804544](https://user-images.githubusercontent.com/38639633/106174486-70e7c600-61d8-11eb-9fed-40b9188df7cf.png)

- ```python
  import numpy as np
  grouped['Points'].agg([np.sum, np.mean, np.std])
  ```

  > 하나의 특정 컬럼에 여러개의 function을 apply 할 수도 있다. 
  >
  > ![image-20210128190047309](https://user-images.githubusercontent.com/38639633/106174524-79d89780-61d8-11eb-9721-2c84c5c7af1c.png)

  <br>

### Transofrmation

- Aggregation과 달리 Key값 별로 요약된 정보가 아님
- 개별 데이터의 변환을 지원한다. 
- $$
  z_i=\frac{x_i-\mu}{\sigma}
  $$

   ```python
   # score로 표준화 함수를 정의한 뒤 transform
   score = lambda x: (x - x.mean()) / x.std()
   grouped.transform(score)
  ```
  > ![image-20210128190503913](https://user-images.githubusercontent.com/38639633/106174558-83fa9600-61d8-11eb-9308-9d7ae00a8c17.png)

### Filter

- 특정 조건으로 데이터를 검색할 때 사용한다. 

  ```python
  df.groupby("Team").filter(lambda x: len(x) >= 3)
  ```

  > filter 안에는 boolean 조건이 존재해야한다.
  >
  > len(x)는 grouped된 dataframe의 개수를 의미한다. 
  >
  > ![image-20210128191447560](https://user-images.githubusercontent.com/38639633/106174580-89f07700-61d8-11eb-92db-2536d3009fe9.png)

<br>

# 2. Case study

> 해당 섹션은 [예제](https://github.com/BoostcampAITech/lecture-note-python-basics-for-ai/blob/main/codes/pandas/part_2/1_groupby_hierarchical_index.ipynb)로 대체한다. 

<br>

# 3. Pivot table

- excel에서의 피벗테이블과 같다. 

- index축은 groupby와 동일하다

- column에 추가로 labeling 값을 추가하여 value에 numeric type 값을 aggregation하는 형태

  ```python
  df_phone = pd.read_csv("./data/phone_data.csv")
  df_phone["date"] = df_phone["date"].apply(dateutil.parser.parse, dayfirst=True)
  df_phone.head()
  ```

  > ![image-20210128192552712](https://user-images.githubusercontent.com/38639633/106174596-8f4dc180-61d8-11eb-9437-6559dcfa9967.png)

  ```python
  df_phone.pivot_table(
      values=["duration"],
      index=[df_phone.month, df_phone.item],
      columns=df_phone.network,
      aggfunc="sum",
      fill_value=0,
  )
  ```

  > ![image-20210128192623488](https://user-images.githubusercontent.com/38639633/106174618-94127580-61d8-11eb-8d8f-1bcbc8bd6abc.png)

  <br>

# 4. Crosstab

- 특히 두 column의 교차 빈도, 비율, 덧셈 등을 구할 때 사용한다. 

- Pivot table의 특수한 형태

- User-Item Rating Matrix 등을 만들 때 사용가능함

  ```python
  df_movie = pd.read_csv("data/movie_rating.csv")
  df_movie.head()
  ```

  > ![image-20210128192828354](https://user-images.githubusercontent.com/38639633/106174639-9a085680-61d8-11eb-896a-3e854feb1e5f.png)

  ```python
  pd.crosstab(
      index=df_movie.critic,
      columns=df_movie.title,
      values=df_movie.rating,
      aggfunc="first",
  ).fillna(0)
  ```

  > ![image-20210128192906252](https://user-images.githubusercontent.com/38639633/106174665-a096ce00-61d8-11eb-8e6c-7105cded1303.png)




<br>



# 5. Merge & Concat

- SQL에서 많이 사용하는 Merge와 같은 기능 
- 두 개의 데이터를 하나로 합침



<br>



## 5.1. pd.merge -  `(on = )`

- `pd.merge(df_a, df_b, on = '컬럼명')`

  > on : 공통적으로 있는 컬럼에 대한 merge 진행

- `pd.merge(df_a, df_b, left_on = '좌측df컬럼명', right_on = '우측df컬럼명')`

  - 두 df의 column명이 다를 때 사용한다.

<br>

## 5.2. join method - `(how = )`

- join method는 총 4가지 방식이 있다. 

  ![image-20210128203251180](https://user-images.githubusercontent.com/38639633/106174692-a7254580-61d8-11eb-87c6-ca702154dd88.png)

  > 더 자세한 코드 예제는 [여기](https://github.com/BoostcampAITech/lecture-note-python-basics-for-ai/blob/main/codes/pandas/part_2/3_merge_concat.ipynb)

- **Index based join**
  - 컬럼명이 아닌 index를 기준으로 merge할 때 사용한다. 
  - 이 경우, 동일 컬럼명이 존재할 시에 `_x`, `_y`가 컬럼명 뒤에 붙는다. (주의)
    
      ```python
      pd.merge(df-a, df_b, right_index = True, left_index = True)
      ```
    
      > ![image-20210128203649741](https://user-images.githubusercontent.com/38639633/106174706-ad1b2680-61d8-11eb-9499-e9bd12574e83.png)
    
      

<br>



## 5.3. Concat

- 같은 형태의 데이터(DataFrame)를 붙이는 연산작업
  - `merge`와 다른 점은 전체를 붙인다는 점에 있다.

  ```python
  df_new = pd.concat([df_a, df_b], axis = 1)
  ```

  >  axis 설정을 통해 위아래로 붙일 건지, 좌우로 붙일 건지를 선택한다. 

  <br>

# 6. Persistence
<br>
## 6.1. Database connection

- Data loading시에 db connection 기능을 제공한다. 
  ```python
  import sqlite3  # pymysql <- 설치
  
  conn = sqlite3.connect("./data/flights.db")
  cur = conn.cursor()
  cur.execute("select * from airlines limit 5;")
  results = cur.fetchall()
  results
  ```
<br>

## 6.2. XLS persistence

- Dataframe의 엑셀 추출코드
- Xls 엔진으로 openpyxls 또는 XlsxWrite 사용
- Install

  ```python
  ### Pandas persistence
  #### install
  - conda install openpyxl
  - conda install XlsxWriter
  - see more http://xlsxwriter.readthedocs.io/working_with_pandas.html
  ```

  ```python
  import pandas as pd
  writer = pd.ExcelWriter("./df_routes.xlsx", engine="xlsxwriter")
  # writer
  df_routes.to_excel(writer, sheet_name="Sheet1")
  writer.close()
  ```

  > **주의!**
  >
  > 마지막 객체를 닫아주는 .close()를 사용해야 파일이 생성된다. 

<br>

## 6.3. Pickle persistence

- 가장 일반적인 python 파일 persistence
- to_picle, read_pickle함수를 사용한다.
  ```python
  df_routes.to_pickle("./data/df_routes.pickle")
  df_routes_pickle = pd.read_pickle("./data/df_routes.pickle")
  df_routes_pickle.head()
  ```
<br>

# 7. 확률론의 필요성

- 딥러닝은 확률론 기반의 기계학습 이론에 바탕을 두고 있습니다 
- 기계학습에서 사용되는 손실함수(loss function)들의 작동원리는 데이터 공간을 통계적으로 해석해서 유도하게됩니다
  - 예측이 틀렸을 때의 위험(risk)을 최소화하도록 데이터를 학습하는 원리는 통계적 기계학습의 기본 원리이다.
- 회귀분석에서 손실함수로 사용되는 $L_2$-노름은 예측 오차의 분산을 가장 최소화하는 방향으로 학습 하도록 유도 한다.
- 분류 문제에서 사용되는 Cross-entropy는 모델 에측의 불확실성을 최소화하는 방향으로 학습하도록 유도한다.
- 분산 및 불확실성을 최소화 하기 위해서는 측정하는 방법을 알아야한다.
  - 두 대상 혹은 집단을 측정하는 방법을 통계학에서 제공한다.

  
<br>

# 8. 확률분포는 데이터의 초상화

- 데이터 공간을 $\mathscr{X}\times\mathscr{Y}$라고 표기하고 $\mathscr{D}$는 데이터 공간에서의 데이터를 추출하는 분포이다.
- 이 때, 데이터는 확률변수 $(\mathbf{x}, y) \sim \mathscr{D}$라고 표기한다.
  - 여기서 $(\mathbf{x}, y)\in\mathscr{X}\times\mathscr{Y}$는 데이터 공간 상의 관측가능한 데이터에 해당한다.
  ![image-20210129012427273](https://user-images.githubusercontent.com/38639633/106174784-c02df680-61d8-11eb-977f-1ba21eb9ea81.png)

<br>  

## 8.1. 이산확률변수 vs 연속확률변수

- 확률변수는 확률분포 $\mathscr{D}$에 따라 이산형(discrete)과 연속형(continuous)확률변수로 구분하게 된다. 
- **이산형 확률변수**는 확률변수가 가질 수 있는 경우의 수를 모두 고려하여 확률을 더해 모델링한다.

  
  $$
  \mathbb{P}(X\in A) = \sum_{\mathbf{x}\in A}P(X=\mathbf{x})
  $$
  
- **연속형 확률변수**는 데이터 공간에 정의된 확률변수의 밀도(density) 위에서 적분을 통해 모델링한다.
  
  $$
  \mathbb{P}(X\in A) = \int_AP(\mathbf{x})d\mathbf{x}
  $$

  > 밀도는 누적확률분포의 변화율을 모델링하며 확률로 해석하면 안된다.

- 결합분포 $P(\mathbf{x},y)$는 $\mathscr{D}$를 모델링한다. 여기서 $\mathscr{D}$는 이론적으로 미리 존재하는 확률분포라고 가정하기 때문에 사전에 알 수 없다. 
- $P(\mathbf{x})$는 입력 $\mathbf{x}$에 대한 주변확률분포(marginal probablility distribution)로 $y$에 대한 정보를 주진 않는다. 
  - 단지, 각 x에 대한 y값의 빈도를 계산하여 분포로 나타낸다.
    ![image-20210129014543679](https://user-images.githubusercontent.com/38639633/106174834-c7550480-61d8-11eb-8d81-652be7fbb1d9.png){:width = "45"}{: .center}

- 조건부확률분포 $P(\mathbf{x} \| y)$ 는 데이터 공간에서 입력 $\mathbf{x}$와 $y$의 관계를 모델링한다. 
  - 특정 클래스 $y$가 주어졌다고 가정했을 때, 데이터의 확률분포를 보여준다. 

<br>



# 9. 조건부확률과 Machine Learning

- 조건부확률 $P(y~\|~\mathbf{x})$는 입력변수 $\mathbf{x}$에 대한 정답이 $y$일 확률을 의미한다. 
  - 연속확률분포의 경우 ~~확률이 아니고~~ 밀도로 해석함을 주의하자.
- 로지스틱회귀에서 사용했던 선형모델과 소프트맥스 함수의 결합은 데이터에서 추출된 패턴을 기반으로 확률을 해석하는데 사용된다.
- 분류문제에서 $softmax(\mathbf{W}\phi+\mathbf{b})$는 데이터 $\mathbf{x}$로부터 추출된 특징패턴 $\phi(\mathbf{x})$과 가중치행렬 $\mathbf{W}$을 통해 조건부확률 $P(y~\|~\mathbf{x})$을 계산한다...
  - $P(y~\|~\phi(\mathbf{x}))$라고 써도 같은 맥락이다. 
- 회귀문제의 경우 조건부기대값 $\mathbb{E}[y~\|~\mathbf{x}]$을 추정한다.
  - 여기서 $\mathbb{E}[y~\|~\mathbf{x}] = \int_yyP(y~\|~\mathbf{x})dy$이다. 
  - 조건부기대값 $\mathbb{E}[y~\|~\mathbf{x}]$은 $\mathbb{E}\|\|y-f(\mathbf{x})\|\|_2$를 최소화하는 함수 $f(x)$와 일치한다.

  <br>

## 9.1. 기대값이란?

- 확률 분포가 주어지면 데이터를 분석하는데 사용 가능한 여러 종류의 통계적 범함수(statistical functional)를 계산할 수 있다.
- 기대값(expectation)은 데이터를 대표하는 통계량이면서 동시에 확률분포를 통해 다른 통계적 범함수를 계산 하는데 사용된다.
 
  > **연속확률분포 :**
  > $$
  > \mathbb{E}_{\mathbf{x}\sim P(\mathbf{x})}[f(\mathbf{x})] = \int_{\mathcal{X}}f(\mathbf{x})P(\mathbf{x})d\mathbf{x}
  > $$
                                                                              
  > **이산확률분포 :**
  > $$
  > \mathbb{E}_{\mathbf{x}\sim P(\mathbf{x})}[f(\mathbf{x})] = \sum_{\mathbf{x}\in\mathcal{X}}f(\mathbf{x})P(\mathbf{x})
  > $$

- 기대값을 통해 분산, 첨도, 왜도, 공분산 등 다양한 통계량을 계산할 수 있다. 
- 딥러닝은 다층신경망(MLP)을 사용하여 데이터로부터 특징패턴 $\phi$을 추출한다.

<br>

# 10. 몬테카를로 샘플링

- 기계학습의 많은 문제들은 확률분포를 명시적으로 모를 때가 대부분이다
- 확률분포를 모를 때 데이터를 이용하여 기대값을 계산 하려면 **몬테카를로(MonteCarlo)** 샘플링 방법을 사용해야한다.
  - 몬테카를로는 이산형, 연속형에 상관없이 성립한다.
- 몬테카를로 샘플링은 **독립추출**만 보장된다면, 대수의 법칙에 의해 수렴을 보장한다.
  $$
  \mathbb{E}_{\mathbf{x}\sim P(\mathbf{x})}[f(\mathbf{x})]\approx \frac{1}{N}\sum^N_{i=1}f(\mathbf{x}^{(i)}),~~ \mathbf{x}^{(i)} \stackrel {i.i.d}{\sim} P(\mathbf{x})
  $$
  

