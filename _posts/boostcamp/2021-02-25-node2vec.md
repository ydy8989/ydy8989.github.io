---
layout: post
title: Node2Vec and Latent Factor Model
subtitle: Netflix Challenge with latent factor model 
gh-repo: ydy8989/ydy8989.github.io
gh-badge: [follow]
categories: [BOOSTCAMP]
tags: [boostcamp, recommendation]
comments: true
---

그래프의 정점을 벡터로 표현하는 방법인 정점 임베딩(Node Embedding)에 대해서 배웁니다. 기계학습의 다양한 툴은 벡터로 표현된 데이터를 입력으로 받습니다. 이번 강의에서는 **그래프의 정점(Node)을 벡터로 표현하는 방법**인 정점 임베딩(Node Embedding)에 대해 배웁니다. **정점을 어떻게 벡터로 표현하는지, 정점 사이의 유사성을 어떻게 표현하는지 집중**하며 공부합니다.



# Node Representation Learning

>  In this section, we study several methods to represent a graph in the embedding space. By “embedding” we mean mapping each node in a network into a low-dimensional space, which will give us insight into nodes’ similarity and network structure. Given the widespread prevalence of graphs on the web and in the physical world, representation learning on graphs plays a significant role in a wide range of applications, such as link prediction and anomaly detection. However, modern machine learning algorithms are designed for simple sequence or grids (e.g., fixed-size images/grids, or text/sequences), networks often have complex topographical structures and multimodel features. We will explore embedding methods to get around the difficulties.



## What is Node Representation?

정점 표현학습 : 그래프의 Vertices를 vector로 표현하는 것

![image](https://user-images.githubusercontent.com/38639633/109171263-f43f0c00-77c4-11eb-8336-b5b93eb25c19.png){:.center}

- 정점 표현 학습(Node Representation Learning)은 `정점 임베딩(Node Embedding)`이라고도 부른다.
- node embedding은 vector 형태의 표현 그 자체를 의미하기도 한다.
- 정점이 표현되는 vector space를 `Embedding Sapce`라고  부른다.
- node representation learning의 `입력(input)`은 graph이다. 
- 주어진 graph의 각 vertex $u$에 대한 embedding, 즉 vector representation $z_u$는 node embedding의 `output`이다.

	![image](https://user-images.githubusercontent.com/38639633/109172819-8693df80-77c6-11eb-8fe6-95cfd569f708.png){:.center}



## The reasons of Node embedding

- node embedding을 진행함으로써 vector 형태의 데이터를 위한 도구를 그래프에 적용할 수 있다. 
	- 많은 분류기, Clustering 알고리즘 등은 벡터 형태로 표현된 instance를 입력으로 받는다.
	- 그래프 정점 분류, 군집 분석 등에 사용할 수 있다. 



## Goal of Node embedding

Node embedding의 목표는 임베딩 공간에서의 유사성이 원래 graph network에서의 유사성과 유사하도록 node를 encoding하는 것에 그 목표를 두고 있다. 즉, graph 내에서 유사도가 높은 두 점은 임베딩 공간에서도 유사도가 높도록 하는 것이 목표이다. 

> The goal of node embedding is to encode nodes so that similarity in the embedding space (e.g., dot product) approximates similarity in the original network, the node embedding algorithms we will explore generally consist of three basic stages:

![image](https://user-images.githubusercontent.com/38639633/109244994-0b144b80-7823-11eb-89ac-211a00b8f6e3.png){:.center}



앞서 node embedding의 목표를 graph와 embedding space에서 유사도를 보존하기 위함으로 설명했다. 그렇다면 여기서 말하는 Graph structure와 embedding space에서의 `유사도`는 각각 어떻게 정의될까?

- Embedding space : **Inner product($z_v^\top z_u = \vert\vert z_u\vert\vert\cdot\vert\vert z_v\vert\vert\cdot cos(\theta)$)**로 유사도를 표현한다. 
- Graph structure : **similarity($u,v$)**
	- 이 때, Graph에서의 두 정점간 유사도를 정의하는 방식은 여러가지가 있다. 
	- 본 포스팅에서는 `Adjency-base`, `distance-based`, `path-based`, `nesting-based`, `random walk based`에 대해 간략히 소개한다.



결국, 정리하자면 Node embedding은 다음 두 단계로 이루어진다고 할 수 있다. 

1. 그래프 구조에서의 similarity define
2. step 1.에서 정의한 similarity가 $z_v^\top z_u$로 수렴하도록 학습하는 단계. 즉, 이 부분에 해당하는 내용을 Loss function으로 사용한다고 생각하면 이해하기 쉽다. 



## Graph similarity

그렇다면 앞서 말한 graph에서의 두 정점의 유사성에 대해 알아보자. 위에서도 언급했듯이 여러 similarity 정의가 있지만, 여기서는 총 5개의 유사도에 대해 설명하고자 한다.



### Adjacency 기반 접근법

두 정점이 인접할 때 유사하다고 간주한다. 즉, 두 정점 $u, v$가 인접하다는 것은 두 정점을 연결하는 edge $(u, v)$가 있음을 의미한다. 

$\vert V\vert$가 $n$인 graph의 [Adjacency matrix](https://ko.wikipedia.org/wiki/%EC%9D%B8%EC%A0%91%ED%96%89%EB%A0%AC) $A_{u,v}$는  $n\times n$의 크기를 가지며 각 정점 $u,v\in V$간에 서로 인접한 경우 1 아닌경우 0으로 표현되는 matrix를 말한다. 이때, 인접행렬(Adjacency matrix)의 두 정점 $u,v$의 유사도로 가정한다. 

이 때의 인접성 기반 접근법의 `손실함수`는 다음과 같다. 


$$
\mathcal{L}=\sum_{(u,v)\in V\times V}\vert\vert z_u^\top z_v - \mathbf{A}_{u,v}\vert\vert^2
$$


즉, 이 손실 함수 $\mathcal{L}$이 최소가 되는 node embedding을 찾는 것을 목표로 한다. 이 loss function의 최소화를 위해서는 (stochastic) gradient descent를 사용한다. 

하지만 이러한 인접성 기반의 유사도 판단은 한계가 있다. 

![image](https://user-images.githubusercontent.com/38639633/109390142-28e0ce00-7953-11eb-87a9-15e8caa63170.png){:.center}

위 그림에서 빨간색점은 파란색 점과의 거리 3이고, 초록색 점은 파란색 점과의 거리가 2로 초록색이 파란색에 더 유사하다고 할 수 있다. 하지만, 직접 연결된 edge가 없기에 adjacency matrix에서의 각 관계를 표현하는 값은 0으로 표현된다. 또한, 군집의 경우에도 고려되지 않는다. 

이러한 인접성 기반 접근법의 한계를 개선하고자 다양한 접근법이 구상되었다. 



### Distance 기반 접근법

거리 기반 접근법은 두 정점 사이의 거리가 충분히 가까운 경우 유사하다고 간주한다. 두 정점의 `기준 거리`를 정해놓고, 두 정점이 **기준 거리** 이내일 때 1 그렇지 않을 때 0으로 간주하는 방식이다. 

![image](https://user-images.githubusercontent.com/38639633/109410790-ca623100-79e0-11eb-9cbb-0eec365ecf01.png){:.center}

 위 그림의 경우, 빨간점과 초록, 파랑은 **유사하고**, 보라색은 그렇지 않다. 



### Path 기반 접근법

경로 기반 접근법에서는 두 정점 사이의 경로가 많을 수록 유사하다고 간주하는 방식이다. 정점 $u$와 $v$ 사이의 Path의 정의는 다음의 두 조건을 만족하는 Sequence라고 할 수 있다. 

- $u$에서 시작해서 $v$에서 끝나야한다. 
- 순열에서 연속된 정점은 간선으로 연결되어야 한다. 



![image](https://user-images.githubusercontent.com/38639633/109410885-89b6e780-79e1-11eb-9215-622de8672b01.png){:.center}

위 그림에서 정점 1에서 8로 가는 path를 살펴보면, 1, 4, 6, 8의 경로를 생각해볼 수 있다. 하지만, 1, 6, 8에서 (1,6)은 직접적인 edge로 연결되어 있지 않으므로 path라고 할 수 없다. 

두 정점 $u$와 $v$ 사이의 경로중 거리가 $k$인 것의 수는 $A_{u,v}^k$와 같다. 이 때, $A_{u,v}$는 $u$와 $v$ 사이의 인접행렬을 말하며, 인접행렬의 $k$ 제곱의 $u$행 $v$열 원소와 같다. 

이 방식에서의 경로기반 접근법 손실함수(loss function)은 다음과 같다. 


$$
\mathcal{L}=\sum_{(u,v)\in V\times V}\vert\vert z_u^\top z_v - \mathbf{A}_{u,v}^k\vert\vert^2
$$


### 중첩 기반 접근법 

두 정점이 많은 이웃을 공유할 수록 유사하다고 간주하는 방식의 접근법이다. 아래 그림에서 빨간색 정점은 파란색 정점과 두 명의 이웃을 공유하기 때문에 유사도는 2가 된다. 

![image](https://user-images.githubusercontent.com/38639633/109411068-a869ae00-79e2-11eb-8e58-5f63760c49c9.png){:.center}

정점 $u$의 이웃 집합을 $N(u)$, 그리고 정점 $v$으 이웃 집합을 $N(v)$라고 할때, 두 정점의 공통 이웃 수 $S_{u,v}$는 다음과 같이 정의된다. 

$$
S_{u,v}=\vert N(u)\cap N(v)\vert=\sum_{w\in N(u)\cap N(v)}1
$$

중첩 기반 접근법의 손실 함수는 다음과 같다. 

$$
\mathcal{L}=\sum_{(u,v)\in V\times V}\vert\vert z_u^\top z_v - S_{u,v}\vert\vert^2
$$

이와 유사하게 자카드 유사도(Jaccard Similarity) 혹은 Adamic adar score를 사용할 수도 있다. 

- 자카드 유사도는 공통 **이웃의 수 대신 비율**을 계산하는 방식이다. 

	
	$$
	\frac{\vert N_u\cap N_v\vert}{\vert N_u\cup N_v\vert}
	$$

- 이 자카드 유사도는 항상 0에서 1 사이의 값을 가진다. 이 때, 1의 값을 가지기 위해서는 두 정점 $u,v$의 이웃들의 집합인 $N(u)$와 $N(v)$가 정확히 같을 때 ($N(u)=N(v)$) 1의 값을 갖는다.
- Adamic Adar 점수는 **공통 이웃 각각에 가중치를 부여**하여 가중 합을 계산하는 방식이다. 

	
	$$
	\sum_{w\in N_u\cap N_v}\frac{1}{d_w}
	$$

- 여기서 $d_w$는 $u$와 $v$가 공통적으로 이웃인 점 $w$의 degree를 의미한다. 
- 예를 들어 $u$와 $v$가 공통으로 follow하는 트와이스 계정 $w$가 있다고 가정하자. 두 점 모두 트와이스 계정을 팔로우하고 있지만, 그렇다고 해서 $u$와 $v$에 큰 유사성을 부여하기는 어렵다. 그 이유는 트와이스 계정을 팔로우하고 있는 수백만 명의 팔로워 중 두 명일 뿐이기 때문이다. 따라서 트와이스 계정 $w$의 degree로 나눠주어 가중치를 줄이는 방식으로 계산을 하게 된다. 



### Random walk 기반 접근법

graph 구조에서 경로와 비슷한 개념인 보행(Walk)에 대해 먼저 정의하자. path와 기본적으로 비슷하지만, 변이 중복될 수 있는 경우를 walk라고 한다. 

> 자세한 설명은 [이 곳](https://en.wikipedia.org/wiki/Path_(graph_theory)#Walk,_trail,_path)에서 확인할 수 있다. Walk, trail, path에 대한 개념을 구분하고 가는 것을 추천한다. 

**임의보행**이란 현재 정점의 이웃 중 하나를 균일한 확률로 선택하는 이동하는 과정을 반복하는 것을 의미한다. 이 방식은 시작 node 주변의 `지역적 정보`와 `그래프 전역 정보`를 모두 고려한다고 할 수 있다. 거리를 제한하지 않고 확률적으로 전 그래프 전체 범위를  검사하기 때문이다. 

![image](https://user-images.githubusercontent.com/38639633/109417981-47a19c00-7a09-11eb-9266-d2f0c55d8a51.png){:.center}

`Random-walk` 기반 접근법은 다음 세 단계를 거친다.

1. 각 정점에서 시작하여 random walk를 반복 수행한다.
2. 각 정점에서 시작한 임의보행 중 도달한 정점들의 리스트를 구성한다. 이 때, **정점 $u$에서 시작한 임의보행 중 도달한 정점들의 리스트를 $N_R(u)$**라고 한다. 한 정점을 여러 번 도달한 경우, 해당 정점은 $N_R(u)$에 여러 번 포함될 수 있다.
3. 다음 손실함수를 최소화하는 임베딩을 학습한다. 
	
	$$
	\mathcal{L}=\sum_{u\in V}\sum_{v\in N_R(u)}-\text{log}(P(v\vert \mathbf{z}_u))
	$$
	
	위 식에서 로그가 씌워지는 확률 $P(v\vert \mathbb{z}_u)$는 $u$에서 시작한 임의보행이 $v$에 도달할 확률을 임베딩으로부터 추정한 결과를 의미한다. 이 확률값은 크면 클 수록 추정을 잘 한 것이다. 


그렇다면 임베딩으로부터 도달 확률을 어떻게 추정할까? 위 손실함수(loss function)에서의 **정점 $u$에서 시작한 임의보행이 정점 $v$에 도달할 확률 $P(v\vert \mathbb{z}_u)$**은 다음과 같이 추청한다.

$$
P(v\vert \mathbb{z}_u)=\frac{exp(z_u^\top z_v)}{\sum_{n\in V}exp(z_u^\top z_v)}
$$


즉, 유사도 $z_u^\top z_v$가 높을 수록 도달 확률이 높다. 결국 식은 다음과 같다. 


$$
\mathcal{L}=\sum_{u\in V}\sum_{v\in N_R(u)}-\text{log}(\frac{exp(z_u^\top z_v)}{\sum_{n\in V}exp(z_u^\top z_v)})
$$

- 여기서 로그가 씌워진 부분은 임베딩으로부터 추정한 도달 확률
- 첫번째 summation(안쪽)은 임의보행 중 마주친 모든 정점에 대한 합산
- 두번째 summation(바깥쪽)은 모든 시작점에 대한 합산

이 손실함수를 완성하고 이를 최소화하는 방식으로 임베딩 학습을 한다. 

---
임의 보행 방법에 따라 `DeepWalk`와 `Node2Vec`이 구분된다. 

- Deepwalk는 앞서 설명한 기본 임의보행을 사용한다. 즉, 현재 정점의 이웃 중 하나를 균일한 확률로 선택하는 이동과정을 반복한다.
- Node2Vec은 `2차 치우친 임의보행(Second-order Biased Random Walk)`를 사용한다. 
	- 여기서 SBRW는 현재 정점 뿐만 아니라 직전에 머문 정점까지 고려하여 다음 정점을 선택하는 방식을 말한다. 
	- 직전 정점의 거리를 기준으로 케이스를 구분하여 차등적인 확률을 부여한다. 
		![image](https://user-images.githubusercontent.com/38639633/109418223-91d74d00-7a0a-11eb-9f93-1f09224d9270.png){:.center}
	- 예를 들어 직전 정점 : $u$, 현재 정점 : $v$일 때, 다음 도달할 정점의 확률은 위와 같은 원리로 차등 부여한다. $x$의 경우는 $u$에서 1이고,  $u$와 $v$의 거리도 1이므로 거리가 `유지되는 방향`이다. 비슷한 원리로 $v$에서 바라봤을 때, $u$는 이전 정점과 `가까워지는 방향`이고, $y$는 `멀어지는 방향`이다.
	- 이 세 가지 방향을 구분하여 확률을 차등 적용하고, 이 방식은 사용자가 지정 가능하다.
	- 이 방식에 따라 전혀 다른 임베딩이 된다.



#### 임베딩에 따른 Node2Vec 예시

아래의 두 예시는 Node2Vec으로 임베딩 수행 후, K-means 군집 분석을 수행한 결과이다.

![image](https://user-images.githubusercontent.com/38639633/109419223-bda90180-7a0f-11eb-94ef-91869bd78eaa.png){:.center}

- `멀어지는 방향`에 높은 확률을 부여한 경우 위와 같은 모습으로 군집이 결정된다. 
- 정점의 역할(bridge, leaf 등)이 같은 경우에 임베딩이 유사하게 된 모습이다.

![image](https://user-images.githubusercontent.com/38639633/109419262-fc3ebc00-7a0f-11eb-853c-6917178fd595.png){:.center}

- `가까워지는 방향`에 높은 확률을 부여한 경우
- 같은 군집에 속한 경우 임베딩이 유사한 모습을 보인다.













 **Further Reading**

- [https://arxiv.org/pdf/1607.00653.pdf](https://arxiv.org/pdf/1607.00653.pdf)
- [https://arxiv.org/pdf/1403.6652.pdf](https://arxiv.org/pdf/1403.6652.pdf)

 