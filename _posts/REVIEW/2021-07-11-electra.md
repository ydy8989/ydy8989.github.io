---
layout: post
title: ELECTRA - Pre-training Text Encoders as Discriminators Rather Than Generators 논문 리뷰
subtitle: Efficiently Learning an Encoder that Classifies Token Replacements Accurately
gh-repo: ydy8989/ydy8989.github.io
gh-badge: [follow]
categories: [NLP]
tags: [nlp, electra, machine translation]
comments: true
---

ICLR 2020에서 구글 리서치 팀이 새로운 pre-training 기법을 적용한 language model인 ELECTRA(**E**fficiently **L**earning an **E**ncoder that **C**lassifies **T**oken **R**eplacements **A**ccurately)를 발표하였다. BERT 이후의 많은 language model은 MLM task를 통해 pre-training을 하게되는데, 이런 모델들은 학습에 많은 시간과 계산량을 필요하므로 컴퓨팅 리소스가 "많이" 필요하다. 

ELECTRA는 모델의 정확도와 더불어 효율성에 포인트를 맞춘 방식의 모델이다. 본 논문에서 학습 효율을 향상하기 위해 새로운 pre-training 방식인 Replaced Token Detection(RTD)라는 방식을 제안하고, 이를 통해 보다 빠르고 효율적으로 학습한다. 

결과적으로 ELECTRA는 동일한 크기, 데이터, 컴퓨팅 리소스 조건에서 BERT의 성능을 능가하였다. Small 모델과 Large 모델을 실험하였고, 각각 GPT나 RoBERTa, XLNet 대비 동일 조건 우수한 성능에 도달하였다. 

**Paper : [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://arxiv.org/abs/2003.10555)**



1. 입력 $x = [x_1, \cdots, x_n]$에 대한 마스킹 위치의 집합 $\mathbb{m}=[m_1, m_2, \dots, m_k]$을 정한다

	- 마스킹의 위치 : $m_i \sim \text{unif} \{1, n\} \text{ for } i = 1 \text { to } k$
	- 마스킹의 개ㅜ : 전체 15%

	

$h(x) = [h_1, \cdots, h_n]$

$x_t = [\text{MASK}]$


$$
p_G(x_t|x) = \frac{\text{exp}(e(x_t)^T h_G(x)_t)}{\sum_{x'} \text{exp}(e(x')^T h_G(x)_t)}
$$


$$D(x, t) = \text{sigmoid}(w^T h_D (x)_t)$$

$x = [x_1, x_2, \cdots, x_n]$



generator는 MLM을 수행하기 위해 훈련된다. 입력 $x = [x_1, x_2, \cdots, x_n]$이 주어졌을 때, MLM은 임의의 위치 집합(정수이며, 1과 $n$ 사이)을 먼저 선택한 뒤, $m = [m_1, \cdots, m_k]$로 마스킹 시킨다(여기서 K는 전통적으로 $[0.15n], 즉 15%의 토큰을 마스킹한다.$). 선택된 위치들의 토큰들은 $[\text{MASK}]$ 토큰으로 교체된다. 우리는 이걸 $x^{\text{masked}} = \text{REPLACE}(x, m, [\text{MASK}])$로 나타낸다. generator는 그 다음 마스킹된 토큰의 원래 정보를 예측하기 위해 학습한다. discriminator는 데이터의 토큰과 generator의 샘플로 대체된 토큰을 구별하기 위해 훈련된다. 좀 더 구체적으로 말하자면, 우리는 마스킹된 토큰을 generator 샘플로 교체하여 변형된 예제 $x^{\text{corrupt}}$를 생성하고, $x^{\text{corrupt}}$가 원래의 입력 $x$가 맞는지 예측하기 위해 discriminator를 훈련한다. 정식으로, 모델 입력은 다음을 따라 만들어진다.

$$m_i \sim \text{unif} \{1, n\} \text{ for } i = 1 \text { to } k \\~\\ x^{\text{masked}} = \text{REPLACE}(x, m, [\text{MASK}]) \\~\\ \hat{x}_i \sim p_G(x_i|x^{\text{masked}}) \text{ for } i \in m \\~\\ x^{\text{corrupt}} = \text{REPLACE}(x, m, \hat{x})$$

그리고 손실 함수는


$$
\mathcal{L}_{\text{MLM}}(\textbf{x}, \theta_G) = \mathbb{E} \left( \sum_{i \in \textbf{m}} -\log p_G (x_i | \textbf{x}^{masked}) \right)
$$

$$
\mathcal{L}_{Disc} (\textbf{x}, \theta_{D}) = \mathbb{E} \left( \sum_{t=1}^{n} -\mathbb{1}(x_{t}^{corrupt} = x_t) \log D(\textbf{x}^{corrupt}, t) - \mathbb{1}(x_{t}^{corrupt} \neq x_t) \log (1-D(\textbf{x}^{corrupt}, t)) \right)
$$


비록 GAN의 훈련 목적과 비슷해보이나 몇 가지 중요한 차이가 있다. 먼저 generator가 우연히 올바른 토큰을 생성해냈다면, 토큰은 '가짜' 대신 '진짜' 로 고려된다. 우리는 이 공식으로 다운스트림 작업에 대한 결과를 적당히 향상시킬 수 있다는 것을 발견했다. 더 중요한 것은, generator는 discriminator를 속이기 위해 적대적으로 훈련받는 것 대신 MLH로 훈련된다. 적대적 훈련은 generator에서 샘플링을 통해 backpropagate 하는 것이 불가능하기 때문에 힘들다. 비록 generator를 훈련하기 위해 강화학습을 사용하는 것으로 이 이슈를 우회적인 방법으로 실험했지만, 이 방법은 MLH보다 성능이 낮았다. 마지막으로 우리는 GAN에서 전형적으로 사용하는 noise vector를 generator에 공급하지 않는다.

손실함수를 결합해 최소화하면


$$
\min_{\theta_G, \theta_D} \sum_{x \in \mathcal{X}} \mathcal{L}_{\text{MLM}}(x, \theta_G) + \lambda\mathcal{L}_{\text{Disc}}(x, \theta_D)
$$


로 표현할 수 있다. $\mathcal{X}$는 raw text. 우리는 하나의 표본으로 손실에 대한 기대치를 대략적으로 계산한다. generator를 통해 discriminator의 손실을 역전파로 계산하지 않는다(사실 못한다. 샘플링 스텝 때문에). 사전 훈련 후에, generator는 버리고 discriminator를 다운스트림 과제에서 미세 조정한다.

